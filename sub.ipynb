{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMppikwsrUvK4bpPXQyhrEL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnjaliAyitham/AI-ML-intern/blob/main/sub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVi5T2OLhvPM",
        "outputId": "9590a87c-045f-4f9d-c0d1-3a00222aa46e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m868.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n",
            "Collecting faster-whisper\n",
            "  Downloading faster_whisper-1.0.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting av<13,>=11.0 (from faster-whisper)\n",
            "  Downloading av-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ctranslate2<5,>=4.0 (from faster-whisper)\n",
            "  Downloading ctranslate2-4.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (179.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.4/179.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.23.1)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.19.1)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster-whisper)\n",
            "  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (1.25.2)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.11.0)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Installing collected packages: humanfriendly, ctranslate2, av, coloredlogs, onnxruntime, faster-whisper\n",
            "Successfully installed av-12.0.0 coloredlogs-15.0.1 ctranslate2-4.2.1 faster-whisper-1.0.2 humanfriendly-10.0 onnxruntime-1.18.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,125 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,376 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [110 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.0 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,084 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,854 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 6,972 kB in 3s (2,756 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 47 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install pytube\n",
        "!pip install ffmpeg-python\n",
        "!pip install faster-whisper\n",
        "!apt-get update\n",
        "!apt-get install -y ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pytube\n",
        "import ffmpeg\n",
        "import time\n",
        "import math\n",
        "from faster_whisper import WhisperModel"
      ],
      "metadata": {
        "id": "aykq0UCehwVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://youtu.be/VUrqddjkxok?si=1HGfpLgEXvMGWHvj\"\n",
        "yt = pytube.YouTube(url)\n",
        "\n",
        "yt.streams.filter(progressive=True,file_extension='mp4').order_by('resolution').desc().first().download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eeJCNIzthwY1",
        "outputId": "c93e34c1-e128-4518-ab95-08e409d40e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Machine Learning Explained In 2 Minutes.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Title: {yt.title}\")\n",
        "print(f\"Views: {yt.views}\")\n",
        "print(f\"Description: {yt.description}\")\n",
        "print(f\"Length: {yt.length} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAtk3GDOhwax",
        "outputId": "03dd5047-11d8-44c7-df3c-d49fb937bddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Machine Learning Explained In 2 Minutes\n",
            "Views: 26205\n",
            "Description: What is Machine Learning?\n",
            "Traditional programming requires human to define set of instructions\n",
            "which requires a tons of code and leave a plenty of room for error.\n",
            "With machine learning, we just need data, a tons of data to be precise. \n",
            "Lucky for us, thanks to internet and smartphones, we have a tons of data.\n",
            "In machine learning, instead of following hard coded instructions, a program can learn from data or adapt its behavior according to experience.\n",
            "\n",
            "We can divide Machine Learning into three broad categories.\n",
            "Supervised learning, Unsupervised learning and Reinforcement learning.\n",
            "\n",
            "Please Like and Subscribe for more weekly videos!\n",
            "\n",
            "Follow me on Twitter: https://twitter.com/thecompscirocks\n",
            "Follow me on Instagram: https://www.instagram.com/thecompscirocks/\n",
            "Follow me on Facebook: https://www.facebook.com/thecompscirocks/\n",
            "\n",
            "Some sources & further reading:\n",
            "https://www.mathworks.com/solutions/machine-learning.html\n",
            "http://www.r2d3.us/visual-intro-to-machine-learning-part-1/\n",
            "https://en.wikipedia.org/wiki/Machine_learning\n",
            "https://en.wikipedia.org/wiki/Supervised_learning\n",
            "https://en.wikipedia.org/wiki/Unsupervised_learning\n",
            "https://en.wikipedia.org/wiki/Cluster_analysis\n",
            "https://en.wikipedia.org/wiki/Reinforcement_learning\n",
            "Length: 139 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the mp4 to the title of the video without a file extension\n",
        "os.rename(yt.title + \".mp4\", yt.title)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YEGkMOL6hwc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract audio from the video\n",
        "def extract_audio(input_file):\n",
        "    extracted_audio = f\"audio-{input_file}.wav\"\n",
        "    stream = ffmpeg.input(input_file)\n",
        "    stream = ffmpeg.output(stream, extracted_audio)\n",
        "    ffmpeg.run(stream, overwrite_output=True)\n",
        "    return extracted_audio\n",
        "audio_extract = extract_audio(yt.title)\n"
      ],
      "metadata": {
        "id": "cWedJyWqhwfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transcribe the audio\n",
        "def transcribe(audio):\n",
        "    model = WhisperModel(\"small\")\n",
        "    segments, info = model.transcribe(audio)\n",
        "    language = info[0]\n",
        "    print(f\" Transcription Language: {language}\")\n",
        "    segments = list(segments) # this is where the transcribe happens\n",
        "\n",
        "    for segment in segments:\n",
        "        print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
        "    return language, segments\n",
        "\n",
        "language, segments = transcribe(audio_extract)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8Ol5bfihwg7",
        "outputId": "af391e24-6233-41b6-8696-984e482e1cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Transcription Language: en\n",
            "[0.00s -> 8.84s]  What is machine learning?\n",
            "[8.84s -> 14.24s]  Let's say we have a picture and we need a program to tell us if there is a banana in\n",
            "[14.24s -> 16.12s]  this picture.\n",
            "[16.12s -> 21.12s]  Traditional programming requires humans to define a set of instructions to recognize\n",
            "[21.12s -> 22.12s]  a banana.\n",
            "[22.12s -> 27.88s]  This would require tons of code and leave plenty of room for error.\n",
            "[27.88s -> 33.20s]  With machine learning, we just need data, tons of data to be precise.\n",
            "[33.20s -> 39.56s]  Lucky for us, thanks to the internet and smartphones, we have tons of data.\n",
            "[39.56s -> 44.92s]  In machine learning, instead of following hard-coded instructions, program can learn\n",
            "[44.92s -> 50.16s]  from data or adapt its behavior according to experience.\n",
            "[50.16s -> 55.80s]  We can divide machine learning into three broad categories.\n",
            "[55.80s -> 61.16s]  Unupervised learning, unsupervised learning and reinforcement learning.\n",
            "[61.16s -> 67.80s]  In supervised learning, we need to provide a data set labeled samples of training data.\n",
            "[67.80s -> 72.72s]  The program will analyze them and should be able to correctly determine labels for new\n",
            "[72.72s -> 74.08s]  data.\n",
            "[74.08s -> 79.20s]  This technique is used for example in speech recognition or by YouTube to recommend you\n",
            "[79.20s -> 81.36s]  a video.\n",
            "[81.36s -> 85.04s]  Unsupervised learning is used when we have unlabeled data.\n",
            "[85.04s -> 90.04s]  The most common unsupervised learning method is cluster analysis.\n",
            "[90.04s -> 95.56s]  It's able to find hidden similarities, patterns or groups.\n",
            "[95.56s -> 101.08s]  Unsupervised learning methods are used for example in bioinformatics for genetic clustering\n",
            "[101.08s -> 103.80s]  or face recognition.\n",
            "[103.80s -> 107.40s]  And last but not least, reinforcement learning.\n",
            "[107.40s -> 110.80s]  This technique is like teaching your dog new trick.\n",
            "[110.80s -> 116.16s]  You provide the program feedback in form of reward and punishment based on which it can\n",
            "[116.16s -> 122.36s]  determine ideal behavior or strategy within a specific context.\n",
            "[122.36s -> 128.40s]  This can be used to teach the program to play poker or control robotic armor.\n",
            "[128.40s -> 130.40s]  Thanks for watching.\n",
            "[130.40s -> 135.32s]  If you enjoyed this video, please hit that like button and don't forget to subscribe\n",
            "[135.32s -> 137.68s]  to see more videos like this in future.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to format time for SRT subtitle files\n",
        "def format_time_for_srt(seconds):\n",
        "    hours = math.floor(seconds / 3600)\n",
        "    seconds %= 3600\n",
        "    minutes = math.floor(seconds / 60)\n",
        "    seconds %= 60\n",
        "    milliseconds = round((seconds - math.floor(seconds)) * 1000)\n",
        "    seconds = math.floor(seconds)\n",
        "    formatted_time = f\"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}\"\n",
        "    return formatted_time"
      ],
      "metadata": {
        "id": "EW_NP0H4hwja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate subtitle file\n",
        "def generate_subtitle_file(input_file, language, segments):\n",
        "    subtitle_file = f\"sub-{input_file}.{language}.srt\"\n",
        "    text = \"\"\n",
        "    for index, segment in enumerate(segments):\n",
        "        segment_start = format_time_for_srt(segment.start)\n",
        "        segment_end = format_time_for_srt(segment.end)\n",
        "        text += f\"{str(index + 1)}\\n\"\n",
        "        text += f\"{segment_start} --> {segment_end}\\n\"\n",
        "        text += f\"{segment.text}\\n\\n\"\n",
        "\n",
        "    with open(subtitle_file, \"w\") as f:\n",
        "        f.write(text)\n",
        "\n",
        "    return subtitle_file\n",
        "\n",
        "subtitle_file = generate_subtitle_file(yt.title, language, segments)"
      ],
      "metadata": {
        "id": "5qfeLUd5hwm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Add subtitle to video\n",
        "def add_subtitle_to_video(input_file, subtitle_file, subtitle_language):\n",
        "    video_input_stream = ffmpeg.input(input_file)\n",
        "    subtitle_input_stream = ffmpeg.input(subtitle_file)\n",
        "    output_video = f\"output-{input_file}-{subtitle_language}.mp4\"\n",
        "    subtitle_track_tile = subtitle_file.replace(\".srt\", \"\")\n",
        "    stream = ffmpeg.output(video_input_stream, output_video,\n",
        "                           vf=f\"subtitles={subtitle_file}\")\n",
        "    ffmpeg.run(stream, overwrite_output=True)\n",
        "\n",
        "add_subtitle_to_video(yt.title, subtitle_file, language)"
      ],
      "metadata": {
        "id": "4kfHnT3aiodC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}